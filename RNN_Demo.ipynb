{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Review Generator\n",
    "RNN demonstration by Jiawei Wang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from textgenrnn import textgenrnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One sample from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"overall\": 5.0, \"verified\": false, \"reviewTime\": \"03 30, 2005\", \"reviewerID\": \"A1REUF3A1YCPHM\", \"asin\": \"0001713353\", \"style\": {\"Format:\": \" Hardcover\"}, \"reviewerName\": \"TW Ervin II\", \"reviewText\": \"The King, the Mice and the Cheese by Nancy Gurney is an excellent children's book.  It is one that I well remember from my own childhood and purchased for my daughter who loves it.\\n\\nIt is about a king who has trouble with rude mice eating his cheese. He consults his wise men and they suggest cats to chase away the mice. The cats become a nuisance, so the wise men recommend the king bring in dogs to chase the cats away.  The cycle goes on until the mice are finally brought back to chase away the elephants, brought in to chase away the lions that'd chased away the dogs.\\n\\nThe story ends in compromise and friendship between the mice and the king.  The story also teaches cause and effect relationships.\\n\\nThe pictures that accompany the story are humorous and memorable.  I was thrilled to discover that it is back in print.  I *highly* recommend it for children ages 2 to 7.\", \"summary\": \"A story children will love and learn from\", \"unixReviewTime\": 1112140800}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_file = '/data/scratch/jwang96/Books_5.json'\n",
    "with open(data_file, 'r') as f:\n",
    "    print(f.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Dataset (10k reviews on Books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "output_file = '/data/scratch/jwang96/books.10k'\n",
    "def extract_corpus(data_file, n):\n",
    "    corpus = \"\"\n",
    "    with open(data_file, 'r') as f:\n",
    "        for i in range(n):\n",
    "            line = f.readline()\n",
    "            try:\n",
    "                js = json.loads(line)\n",
    "                revtxt = js['reviewText']\n",
    "                score = js['overall']\n",
    "                revtxt = revtxt.replace('\\n', ' ')\n",
    "                corpus += str(score)+': '+revtxt\n",
    "                corpus += '\\n'\n",
    "            except:\n",
    "                continue\n",
    "    return corpus\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(extract_corpus(data_file, 10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune the model based on pretrained model\n",
    "We perform fine-tuning separately on Cheaha. See the training code on rnn_train.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 40, 100)      46500       input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "rnn_1 (LSTM)                    (None, 40, 128)      117248      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "rnn_2 (LSTM)                    (None, 40, 128)      131584      rnn_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "rnn_concat (Concatenate)        (None, 40, 356)      0           embedding[0][0]                  \n",
      "                                                                 rnn_1[0][0]                      \n",
      "                                                                 rnn_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "attention (AttentionWeightedAve (None, 356)          356         rnn_concat[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 465)          166005      attention[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 461,693\n",
      "Trainable params: 461,693\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "weight_file = 'rnn-10k_weights.hdf5'\n",
    "textgen = textgenrnn(weight_file)\n",
    "textgen.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example output:\n",
    "Generates review text from Ranking 1 to 5 star."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0: Great book we see that it was approvenes to see how the most presented to the ship readable.  The situation, this is a creation of the Narnia series.  The only and come to read this book in the series.  I recommend this book to my very well written book accounts it words.  I have read this ser\n",
      "\n",
      "2.0: I read 2 stars to the series and I did with them.  2.  I was a time for my kids who are a strange series, and the opportunity to see the story books and the second in fact in a story that seems to be the programmer explore new it in the story.  The stars is almost as the story and true and the\n",
      "\n",
      "3.0: I have always loved this book for my grandson.  The book is very fun to read this book and I read to those has no other book to the book and the story makes a Marilyn fan of the symbolism story and typically and I was all again! <|endoftext thourner then officials, altl a college story line?  \n",
      "\n",
      "4.0: This book is a fun book! <|endoftext) is the seing to say that it  I was a lot phililized to read to them and the book is about a blessed at the same time down.  I think this was hard to learn about more than a true.  I was like to be enjoyed by the same children.  The much of the book is a bi\n",
      "\n",
      "5.0: I love this book and I read this book as a wonderful story. I have read them all this book for disappointment. <|endoftext is the wars to read books as  and that in the book is a bit kingdom when the real work is a heart and the book is a good read. <|endoftext wanted to Chreobbattly word s th\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textgen.generate(prefix='1.0')\n",
    "textgen.generate(prefix='2.0')\n",
    "textgen.generate(prefix='3.0')\n",
    "textgen.generate(prefix='4.0')\n",
    "textgen.generate(prefix='5.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generates review text from specific products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0: The Harry Potter book is a great book at all.  I was remembered.  I read this book since I was the older side of this book that is God up a world of the story by the best book in the series.  I did not read it as a said and I was a fantastic story because it was disappointed.  I'm not sure tha\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textgen.generate(prefix='5.0: The Harry Potter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0: The Twilightical Church has been a difficult great manager.  I should have enjoyed , and the story does not be a few times because of the story of a bit of a simply adult thing and thought that the book or time was born, and the book is a really amazing read... <|endoftext work treatment of th\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textgen.generate(prefix='5.0: The Twilight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "As we can see at the output example, RNN generated text is not good. \n",
    "- In terms of relatedness, these generated results lost track of contents. \n",
    "- In terms of grammar, we use Grammarly (Automated Grammar checker) to check its correctness; they received an overall score of 65/83/59.\n",
    "\n",
    "## Summary\n",
    "\n",
    "As a baseline, the RNN model succeeds in generating review texts that look like a reviewer. However, it does not perform well in terms of content relatedness. Maybe we need a model that understands better in context, such as a Transformer-related model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-tf",
   "language": "python",
   "name": "local-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
